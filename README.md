# ğŸ“˜ Aula: IntroduÃ§Ã£o Ã  Engenharia de Dados com Azure

**DuraÃ§Ã£o:** 3 horas  
**PÃºblico-alvo:** Iniciantes (0 conhecimento prÃ©vio)  
**Base:** Livro "Fundamentos da Engenharia de Dados"  
**Plataforma:** Microsoft Azure  
**Objetivo:** Apresentar de forma clara e prÃ¡tica os fundamentos da Engenharia de Dados e aplicar conceitos usando Azure SQL, Data Lake e Data Factory.

---

## ğŸ§­ Roteiro Geral da Aula

| Bloco | Tema | DuraÃ§Ã£o | Objetivo |
|-------|------|---------|----------|
| 1 | Abertura + Agenda + IntroduÃ§Ã£o | 10 min | Engajar, alinhar expectativas |
| 2 | DiferenÃ§as entre Engenharia, AnÃ¡lise e CiÃªncia de Dados | 15 min | Entender papÃ©is e responsabilidades |
| 3 | Fundamentos da Engenharia de Dados | 30 min | Teoria: ciclo de vida e elementos essenciais |
| 4 | DemonstraÃ§Ã£o 1: Azure Data Lake + Azure SQL | 25 min | Mostrar armazenamento e ingestÃ£o |
| 5 | DemonstraÃ§Ã£o 2: Azure Data Factory | 25 min | Mostrar transformaÃ§Ã£o e orquestraÃ§Ã£o |
| 6 | Hands-on Orientado (Lab ou Guiado) | 40 min | Atividade prÃ¡tica bÃ¡sica no Azure |
| 7 | ConclusÃ£o + Dicas + Perguntas | 15 min | Recapitular e abrir para dÃºvidas |

---

## ğŸ‘¥ DiferenÃ§a entre Engenharia, AnÃ¡lise e CiÃªncia de Dados (15 min)

| Papel | Foco | EntregÃ¡vel | Ferramentas |
|-------|------|------------|-------------|
| **Engenheiro de Dados** | Infraestrutura e pipelines | Bases estruturadas e acessÃ­veis | Spark, SQL, Data Factory |
| **Analista de Dados** | ExploraÃ§Ã£o e relatÃ³rios | Dashboards e KPIs | Power BI, Excel, SQL |
| **Cientista de Dados** | Modelagem preditiva | Modelos e previsÃµes | Python, ML, Jupyter |

> ğŸ’¡ **Resumo:**  
> O engenheiro prepara e entrega os dados.  
> O analista consome e interpreta.  
> O cientista modela e prevÃª.

---

## âš™ï¸ Fundamentos da Engenharia de Dados (30 min)

### ğŸ” Ciclo de Vida

1. **GeraÃ§Ã£o de dados**: sistemas, sensores, APIs
2. **Armazenamento**: Data Lakes, bancos relacionais
3. **IngestÃ£o**: movimentar dados (batch, streaming)
4. **TransformaÃ§Ã£o**: limpeza, padronizaÃ§Ã£o, enriquecimento
5. **DisponibilizaÃ§Ã£o**: camadas de consumo (BI, APIs)

### ğŸ”§ Elementos Subjacentes

- **SeguranÃ§a**: controle de acesso, criptografia, compliance
- **Engenharia de Dados como Disciplina**: versionamento, testes
- **DataOps**: automaÃ§Ã£o, deploy, CI/CD
- **Arquitetura de Dados**: modular, escalÃ¡vel, eficiente
- **OrquestraÃ§Ã£o**: controle de fluxo e dependÃªncias
- **Engenharia de Software**: cÃ³digo limpo, funÃ§Ãµes reutilizÃ¡veis

---

## ğŸ’» DemonstraÃ§Ã£o 1 â€“ Azure Data Lake + Azure SQL (25 min)

### Objetivo:
Mostrar armazenamento e ingestÃ£o de dados

### Etapas:
- Criar container no **Azure Data Lake Storage Gen2**
- Upload de um arquivo CSV
- Criar banco e tabela simples no **Azure SQL Database**
- Visualizar os dados carregados

> ğŸ’¡ Conceitos explicados: Data Lake como Bronze, Azure SQL como Silver/Gold

---

## ğŸ”„ DemonstraÃ§Ã£o 2 â€“ Azure Data Factory (25 min)

### Objetivo:
Mostrar orquestraÃ§Ã£o e transformaÃ§Ã£o

### Etapas:
- Criar pipeline no **Azure Data Factory**
  - Fonte: Data Lake (CSV)
  - Destino: Azure SQL
- Configurar Linked Services, Datasets e Activities
- Executar e monitorar

> ğŸ’¡ Pipeline simples mas didÃ¡tico mostrando ETL no Azure

---

## ğŸ› ï¸ Hands-on Orientado (40 min)

<img width="2486" height="1496" alt="image" src="https://github.com/user-attachments/assets/b8ee926d-70d1-43a7-a5b5-6c2aaec74c92" />
> ### Brazilian E-Commerce Public Dataset by Olist
> https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce

```python
# Install dependencies as needed:
# pip install kagglehub[pandas-datasets]
import kagglehub
from kagglehub import KaggleDatasetAdapter

# Set the path to the file you'd like to load
file_path = ""

# Load the latest version
df = kagglehub.load_dataset(
  KaggleDatasetAdapter.PANDAS,
  "olistbr/brazilian-ecommerce",
  file_path,
  # Provide any additional arguments like 
  # sql_query or pandas_kwargs. See the 
  # documenation for more information:
  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas
)

print("First 5 records:", df.head())
```

### Tarefa: Executar como tutorial guiado caso os alunos nÃ£o tenham acesso.
1. Criar container no Data Lake
2. Fazer upload de CSV ou extrair via API Kaggle
3. Criar pipeline no ADF
4. Ingerir dados para Postgres SQL
5. Verificar resultado via query

---

## âœ… ConclusÃ£o e RecomendaÃ§Ãµes (15 min)

### RecapitulaÃ§Ã£o:
- DiferenÃ§as entre os papÃ©is de dados
- Ciclo de vida da Engenharia de Dados
- Ferramentas usadas: Data Lake, SQL, Data Factory
- DemonstraÃ§Ãµes prÃ¡ticas realizadas

### ğŸ“š Materiais para Estudo:
- Livro **"Fundamentos da Engenharia de Dados"**
- Curso Microsoft Learn â€“ **Azure Fundamentals**
- Curso gratuito: **DP-900** (Azure Data Fundamentals)

---

## ğŸ§¾ Materiais de Apoio

- Slides com resumo teÃ³rico (PDF ou PPT)
- Scripts SQL utilizados
- JSON de pipeline do ADF (exportÃ¡vel)
- Dataset CSV de exemplo
- Passo a passo das demonstraÃ§Ãµes

---

### âœ‰ï¸ Frase final:

> â€œEngenharia de dados Ã© o que torna possÃ­vel transformar dados brutos em decisÃµes valiosas. Sem estrutura, nÃ£o hÃ¡ valor.â€

